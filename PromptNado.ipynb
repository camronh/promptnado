{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-anthropic langsmith python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_system_prompt = \"\"\"You are a helpful assistant\n",
    "\n",
    "Rules:\n",
    "- You are only allowed to talk about coding\n",
    "- <HERE>\n",
    "- Try to be concise\"\"\"\n",
    "\n",
    "example_instruction = \"The agent should only respond in English. No other languages\"\n",
    "\n",
    "examples = [\"Hola, como estas?\", \"Hi there!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith import evaluate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Schemas\n",
    "\n",
    "\n",
    "class Rule(BaseModel):\n",
    "    \"\"\"A single rule for the prompt\"\"\"\n",
    "    reasoning: str = Field(\n",
    "        ..., description=\"The thought process and direction for why we think this is a good solution to the instruction.\")\n",
    "    prompt: str = Field(..., description=\"A single prompt rule that we can try to solve for the instruction. \\\n",
    "This prompt rule will be interpolated into the system prompt over the <HERE> token.\")\n",
    "\n",
    "\n",
    "class Rules(BaseModel):\n",
    "    \"\"\"Set of prompt rules that should be tried\"\"\"\n",
    "    rules: List[Rule] = Field(\n",
    "        ..., description=\"A list of prompt rules that we can try to solve for the instruction.\")\n",
    "\n",
    "\n",
    "class CorrectnessEvaluationResult(BaseModel):\n",
    "    \"\"\"Result of an evaluation of correctness\"\"\"\n",
    "    reasoning: str = Field(\n",
    "        ..., description=\"The thought process behind why you think the answer is correct or incorrect.\")\n",
    "    correct: bool = Field(..., description=\"Correctness score\")\n",
    "\n",
    "\n",
    "class Promptnado:\n",
    "    def __init__(self, system_prompt: str, instruction: str, examples: List[str], rule_token=\"<HERE>\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.instruction = instruction\n",
    "        self.examples = examples\n",
    "        self.rule_token = rule_token\n",
    "\n",
    "        # Create random dataset name\n",
    "        self.dataset_name = f\"Promptnado_{random.randint(0, 1000000)}\"\n",
    "\n",
    "        self.attempts = 1\n",
    "        self.solved = False\n",
    "        self.current_rule = None\n",
    "        self.current_prompt = None\n",
    "        self.successful_prompt = None\n",
    "\n",
    "    def _create_dataset(self):\n",
    "        \"\"\"Create a dataset with a unique name\"\"\"\n",
    "        dataset = client.create_dataset(\n",
    "            self.dataset_name, description=self.instruction)\n",
    "        for example in self.examples:\n",
    "            client.create_example(\n",
    "                inputs={\"input\": example}, dataset_id=dataset.id)\n",
    "\n",
    "        self.dataset = dataset\n",
    "        print(\n",
    "            f\"Created dataset: {self.dataset_name} with {len(self.examples)} examples\")\n",
    "        return dataset\n",
    "\n",
    "    def _generate_rules(self):\n",
    "        \"\"\"Use an LLM to generate a list of rules\"\"\"\n",
    "\n",
    "        system_prompt = f\"\"\"You are an expert LLM Prompt Engineer. Your job is to try to solve for the provided <Instructions> \\\n",
    "by making adjustments to the <Original Prompt>. You should attempt to make 5 suggestions for prompts that might work. Each suggestion you \\\n",
    "make will be interpolated into the prompt where {self.rule_token} is, and then evaluated for correctness against a dataset of \\\n",
    "examples.\n",
    "\n",
    "<Instructions>\n",
    "{self.instruction}\n",
    "</Instructions>\n",
    "\n",
    "<Original Prompt>\n",
    "{self.system_prompt}\n",
    "</Original Prompt>\n",
    "\"\"\"\n",
    "\n",
    "        structured_llm = init_chat_model(\n",
    "            model=\"gpt-4o\", temperature=0.7).with_structured_output(Rules)\n",
    "\n",
    "        rules: Rules = structured_llm.invoke(system_prompt)\n",
    "\n",
    "        self.rules = rules.rules\n",
    "        print(f\"Generated {len(self.rules)} rules\\n\")\n",
    "        print(self.rules)\n",
    "        return self.rules\n",
    "\n",
    "    def _build_prompt(self, rule: Rule):\n",
    "        \"\"\"Interpolate the rules into the system prompt\"\"\"\n",
    "        interpolated_prompt = self.system_prompt.replace(\n",
    "            self.rule_token, rule.prompt)\n",
    "\n",
    "        print(f\"Interpolated prompt:\\n\\n{interpolated_prompt}\")\n",
    "        return interpolated_prompt\n",
    "\n",
    "    def _evaluate_correctness(self, run: Run, example: Example):\n",
    "        \"\"\"Eval function to use an LLM to validate that the instruction was followed\"\"\"\n",
    "        system_prompt = f\"\"\"Your job is to validate whether the <Result> meets the criteria for <Instruction>. Try to be a harsh judge.\n",
    "\n",
    "<Instruction>\n",
    "{self.instruction}\n",
    "</Instruction>\n",
    "\n",
    "<Result>\n",
    "{run.outputs[\"output\"]}\n",
    "</Result>\n",
    "\"\"\"\n",
    "\n",
    "        structured_llm = init_chat_model(\n",
    "            model=\"gpt-4o\", temperature=0).with_structured_output(CorrectnessEvaluationResult)\n",
    "\n",
    "        result: CorrectnessEvaluationResult = structured_llm.invoke(\n",
    "            system_prompt)\n",
    "\n",
    "        return {\"score\": 1 if result.correct else 0, \"key\": \"correctness\", \"comment\": result.reasoning}\n",
    "\n",
    "    def _predict(self, inputs: dict):\n",
    "        \"\"\"Run current prompt against example in the dataset\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=self.current_prompt),\n",
    "            HumanMessage(content=inputs[\"input\"]),\n",
    "        ]\n",
    "\n",
    "        # Invoke the model\n",
    "        llm = init_chat_model(model=\"gpt-4o\", temperature=0.7)\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        return {\"output\": response.content}\n",
    "    \n",
    "    def _is_solved(self, eval_results):\n",
    "        \"\"\"Validate the results\"\"\"\n",
    "\n",
    "        results = eval_results._results\n",
    "\n",
    "        # If any of the result scores are not a 1, return false\n",
    "        for result in results:\n",
    "            score = result['evaluation_results'][\"results\"][0].score\n",
    "            if score != 1:\n",
    "                return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def _test_rule(self, rule: Rule):\n",
    "        \"\"\"Evaluate a given rule\"\"\"\n",
    "        print(f\"\\nTesting rule: {rule.prompt}\")\n",
    "        self.current_rule = rule\n",
    "\n",
    "        self.current_prompt = self._build_prompt(self.current_rule)\n",
    "\n",
    "        results = evaluate(\n",
    "            self._predict,\n",
    "            data=self.dataset_name,\n",
    "            evaluators=[self._evaluate_correctness],\n",
    "            experiment_prefix=f\"Attempt-{self.attempts}\",\n",
    "        )\n",
    "\n",
    "        self.attempts += 1\n",
    "\n",
    "        return results\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the promptnado\"\"\"\n",
    "        print(f\"Running Promptnado with instruction: {self.instruction}\")\n",
    "        # Create the dataset\n",
    "        self._create_dataset()\n",
    "\n",
    "        while self.solved == False:\n",
    "            # Get a list of rules\n",
    "            self._generate_rules()\n",
    "\n",
    "            # For each rule\n",
    "            for rule in self.rules:\n",
    "                results = self._test_rule(rule)\n",
    "\n",
    "                # Add results validation here\n",
    "                if self._is_solved(results):\n",
    "                    self.results = results\n",
    "                    self.solved = True\n",
    "                    self.successful_prompt = self.current_prompt\n",
    "                    break\n",
    "\n",
    "        print(\"\\n\\nSolved!! Current prompt can be found at `self.successful_prompt`\\n\\n\")\n",
    "\n",
    "        print(f\"Successful prompt:\\n====================\\n{self.current_prompt}\\n=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Promptnado with instruction: The agent should only respond in English. No other languages\n",
      "Created dataset: Promptnado_854125 with 2 examples\n",
      "Generated 5 rules\n",
      "\n",
      "[Rule(reasoning='By explicitly stating that the agent should respond only in English, we can ensure adherence to the instruction.', prompt='You should respond only in English.'), Rule(reasoning='This rule reinforces the language constraint by prohibiting responses in any other language.', prompt='Do not respond in any language other than English.'), Rule(reasoning='By specifying the language of responses, we can make it clear that English is the only acceptable language for communication.', prompt='All responses must be in English.'), Rule(reasoning='This rule makes it explicit that the agent must not use any language other than English.', prompt='Avoid any language other than English in your responses.'), Rule(reasoning='This rule emphasizes that English is the only language permitted for responses, ensuring clarity.', prompt='Only use English when responding.')]\n",
      "\n",
      "Testing rule: You should respond only in English.\n",
      "Interpolated prompt:\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "Rules:\n",
      "- You are only allowed to talk about coding\n",
      "- You should respond only in English.\n",
      "- Try to be concise\n",
      "View the evaluation results for experiment: 'Attempt-1-c82cda41' at:\n",
      "https://smith.langchain.com/o/d967989d-4221-53db-b0a5-665b504acba2/datasets/2be46544-69db-4296-98bf-8971c9ddaaad/compare?selectedSessions=286b5ce9-cf3d-440c-a68b-ac4e599eeb69\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Solved!! Current prompt can be found at `self.successful_prompt`\n",
      "\n",
      "\n",
      "Successful prompt:\n",
      "====================\n",
      "You are a helpful assistant\n",
      "\n",
      "Rules:\n",
      "- You are only allowed to talk about coding\n",
      "- You should respond only in English.\n",
      "- Try to be concise\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pn = Promptnado(example_system_prompt, example_instruction, examples)\n",
    "pn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant\\n\\nRules:\\n- You are only allowed to talk about coding\\n- You should only respond in English.\\n- Try to be concise'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.current_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
