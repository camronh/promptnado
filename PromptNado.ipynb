{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-core langchain-openai langsmith python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_system_prompt = \"\"\"You are a helpful assistant\n",
    "\n",
    "Rules:\n",
    "- You are only allowed to talk about coding\n",
    "- <HERE>\n",
    "- Try to be concise\"\"\"\n",
    "\n",
    "example_instruction = \"The agent should only respond in English. No other languages\"\n",
    "\n",
    "examples = [\"Hola, como estas?\", \"Hi there!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith import evaluate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class Promptnado:\n",
    "    def __init__(self, system_prompt: str, instruction: str, examples: List[str], rule_token=\"<HERE>\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.instruction = instruction\n",
    "        self.examples = examples\n",
    "        self.rule_token = rule_token\n",
    "\n",
    "        # Create random dataset name\n",
    "        self.dataset_name = f\"Promptnado_{random.randint(0, 1000000)}\"\n",
    "\n",
    "        self.attempts = 1\n",
    "        self.solved = False\n",
    "\n",
    "    def _create_dataset(self):\n",
    "        \"\"\"Create a dataset with a unique name\"\"\"\n",
    "        # client.create_dataset(self.dataset_name, description=self.instruction)\n",
    "        print(f\"Created dataset {self.dataset_name}\")\n",
    "\n",
    "    def _generate_rules(self):\n",
    "        \"\"\"Use an LLM to generate a list of rules\"\"\"\n",
    "\n",
    "        self.rules = [\n",
    "            \"English!\",\n",
    "            \"Do not respond in any language besides english. The user is allowed to speak whatever language they like.\"\n",
    "        ]\n",
    "        return self.rules\n",
    "\n",
    "    def _build_prompt(self, rule: str):\n",
    "        \"\"\"Interpolate the rules into the system prompt\"\"\"\n",
    "        interpolated_prompt = self.system_prompt.replace(self.rule_token, rule)\n",
    "\n",
    "        return interpolated_prompt\n",
    "\n",
    "    def _evaluate_correctness(self, run: Run, example: Example):\n",
    "        \"\"\"Eval function to use an LLM to validate that the instruction was followed\"\"\"\n",
    "        return {\"score\": 0, \"key\": \"correctness\"}\n",
    "\n",
    "    def _predict(self, inputs: dict):\n",
    "        \"\"\"Predict the next rule\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=self.current_prompt),\n",
    "            HumanMessage(content=inputs[\"input\"]),\n",
    "        ]\n",
    "\n",
    "        # Invoke the model\n",
    "\n",
    "        # Return the results\n",
    "        \"Hi there!\"\n",
    "\n",
    "    def _test_rule(self, rule: str):\n",
    "        \"\"\"Evaluate a given rule\"\"\"\n",
    "        self.current_rule = rule\n",
    "\n",
    "        self.current_prompt = self._build_prompt(self.current_rule)\n",
    "\n",
    "        results = evaluate(\n",
    "            self._predict,\n",
    "            data=self.dataset_name,\n",
    "            evaluators=[self._evaluate_correctness],\n",
    "            experiment_prefix=f\"Attempt-{self.attempts}\",\n",
    "        )\n",
    "\n",
    "        self.attempts += 1\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the promptnado\"\"\"\n",
    "        # Create the dataset\n",
    "        self._create_dataset()\n",
    "\n",
    "        while self.solved == False:\n",
    "            # Get a list of rules\n",
    "            self._generate_rules()\n",
    "\n",
    "            # For each rule\n",
    "            for rule in self.rules:\n",
    "                results = self._test_rule(rule)\n",
    "\n",
    "                # If the results are satisfactory, break\n",
    "                if results[\"correctness\"] > 0.9:\n",
    "                    self.solved = True\n",
    "                    break\n",
    "\n",
    "        print(\"\\n\\nSolved!! Current prompt can be found at `self.current_prompt\\n\\n\")\n",
    "\n",
    "        print(f\"Current prompt:\\n\\n{self.current_prompt}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
