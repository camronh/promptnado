{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langsmith python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langsmith import Client\n",
    "client = Client()\n",
    "from langchain.schema import SystemMessage, HumanMessage, BaseMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_system_prompt = \"\"\"You are a helpful assistant. \n",
    "\n",
    "Rules:\n",
    "- You are only allowed to talk about coding\n",
    "- <HERE>\n",
    "- Try to be concise\"\"\"\n",
    "\n",
    "example_instruction = \"The agent should only respond in English.\"\n",
    "\n",
    "examples = [[AIMessage(content=\"Hola, como estas?\")], \"Hi there!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camron/Documents/Dev/promptnado/.venv/lib/python3.10/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `init_chat_model` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "import random\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith import evaluate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from schemas import Rule, Rules, CorrectnessEvaluationResult\n",
    "\n",
    "\n",
    "class Promptnado:\n",
    "    def __init__(self, system_prompt: str, instruction: str, examples: List[Union[str, List[BaseMessage]]],\n",
    "                 rule_token=\"<HERE>\", max_attempts=10,\n",
    "                 rule_gen_model=init_chat_model(\n",
    "                     \"gpt-4o-mini\", temperature=0.7),\n",
    "                 eval_model=init_chat_model(\"gpt-4o-mini\", temperature=0.7),\n",
    "                 prediction_model=init_chat_model(\"gpt-4o-mini\", temperature=0.7)):\n",
    "        \n",
    "        # rule_token is not in the prompt throw\n",
    "        if rule_token not in system_prompt:\n",
    "            raise ValueError(f\"Rule token {rule_token} not found in system prompt\")\n",
    "        \n",
    "        self.system_prompt = system_prompt\n",
    "        self.instruction = instruction\n",
    "        self.examples = examples\n",
    "        self.rule_token = rule_token\n",
    "\n",
    "        # Create random dataset name\n",
    "        self.dataset_name = f\"Promptnado_{random.randint(0, 1000000)}\"\n",
    "\n",
    "        self.attempts = 1\n",
    "        self.solved = False\n",
    "        self.current_rule = None\n",
    "        self.current_prompt = None\n",
    "        self.successful_prompt = None\n",
    "        self.rule_gen_model = rule_gen_model\n",
    "        self.eval_model = eval_model\n",
    "        self.prediction_model = prediction_model\n",
    "        self.max_attempts = max_attempts\n",
    "\n",
    "\n",
    "    def _create_dataset(self):\n",
    "        \"\"\"Create a dataset with a unique name\"\"\"\n",
    "        dataset = client.create_dataset(self.dataset_name, description=self.instruction)\n",
    "        for example in self.examples:\n",
    "            if isinstance(example, str):\n",
    "                client.create_example(inputs={\"inputs\": example}, dataset_id=dataset.id)\n",
    "            elif isinstance(example, list) and all(isinstance(msg, BaseMessage) for msg in example):\n",
    "                client.create_example(inputs={\"inputs\": example}, dataset_id=dataset.id)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid example format. Must be a string or a list of BaseMessages.\")\n",
    "\n",
    "        self.dataset = dataset\n",
    "        print(f\"Created dataset: {self.dataset_name} with {len(self.examples)} examples\")\n",
    "        return dataset\n",
    "\n",
    "    def _generate_rules(self):\n",
    "        \"\"\"Use an LLM to generate a list of rules\"\"\"\n",
    "\n",
    "        system_prompt = f\"\"\"You are an expert LLM Prompt Engineer. Your job is to try to solve for the provided <Instructions> \\\n",
    "by making adjustments to the <Original Prompt>. You should attempt to make 5 suggestions for prompts that might work. Each suggestion you \\\n",
    "make will be interpolated into the prompt where {self.rule_token} is, and then evaluated for correctness against a dataset of \\\n",
    "examples.\n",
    "\n",
    "<Instructions>\n",
    "{self.instruction}\n",
    "</Instructions>\n",
    "\n",
    "<Original Prompt>\n",
    "{self.system_prompt}\n",
    "</Original Prompt>\n",
    "\"\"\"\n",
    "\n",
    "        structured_llm = self.rule_gen_model.with_structured_output(Rules)\n",
    "\n",
    "        rules: Rules = structured_llm.invoke(system_prompt)\n",
    "\n",
    "        self.rules = rules.rules\n",
    "        print(f\"Generated {len(self.rules)} rules\\n\")\n",
    "        print(self.rules)\n",
    "        return self.rules\n",
    "\n",
    "    def _build_prompt(self, rule: Rule):\n",
    "        \"\"\"Interpolate the rules into the system prompt\"\"\"\n",
    "        interpolated_prompt = self.system_prompt.replace(\n",
    "            self.rule_token, rule.prompt)\n",
    "\n",
    "        print(f\"Interpolated prompt:\\n\\n{interpolated_prompt}\")\n",
    "        return interpolated_prompt\n",
    "\n",
    "    def _evaluate_correctness(self, run: Run, example: Example):\n",
    "        \"\"\"Eval function to use an LLM to validate that the instruction was followed\"\"\"\n",
    "        system_prompt = f\"\"\"Your job is to validate whether the <Result> meets the criteria for <Instruction>. Try to be a harsh judge.\n",
    "\n",
    "<Instruction>\n",
    "{self.instruction}\n",
    "</Instruction>\n",
    "\n",
    "<Result>\n",
    "{run.outputs[\"output\"]}\n",
    "</Result>\n",
    "\"\"\"\n",
    "\n",
    "        structured_llm = self.eval_model.with_structured_output(\n",
    "            CorrectnessEvaluationResult)\n",
    "\n",
    "        result: CorrectnessEvaluationResult = structured_llm.invoke(\n",
    "            system_prompt)\n",
    "\n",
    "        return {\"score\": 1 if result.correct else 0, \"key\": \"correctness\", \"comment\": result.reasoning}\n",
    "\n",
    "\n",
    "    def _predict(self, inputs: dict):\n",
    "        \"\"\"Run current prompt against example in the dataset\"\"\"\n",
    "        try:\n",
    "            if isinstance(inputs[\"inputs\"], str):\n",
    "                messages = [\n",
    "                    SystemMessage(content=self.current_prompt),\n",
    "                    HumanMessage(content=inputs[\"inputs\"]),\n",
    "                ]\n",
    "                \n",
    "            elif isinstance(inputs[\"inputs\"], list):\n",
    "                messages = [SystemMessage(content=self.current_prompt)]\n",
    "                for msg_dict in inputs[\"inputs\"]:\n",
    "                    if isinstance(msg_dict, dict):\n",
    "                        if msg_dict[\"type\"] == \"human\":\n",
    "                            messages.append(HumanMessage(**msg_dict))\n",
    "                        elif msg_dict[\"type\"] == \"ai\":\n",
    "                            messages.append(AIMessage(**msg_dict))\n",
    "                        else:\n",
    "                            messages.append(BaseMessage(**msg_dict))\n",
    "                    elif isinstance(msg_dict, BaseMessage):\n",
    "                        messages.append(msg_dict)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Invalid message format: {msg_dict}\")\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input format\")\n",
    "\n",
    "\n",
    "            # Invoke the model\n",
    "            response = self.prediction_model.invoke(messages)\n",
    "            if response.tool_calls:\n",
    "                return {\"output\": f\"Tool Calls:\\n{response.tool_calls}\"}\n",
    "\n",
    "            return {\"output\": response.content}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def _is_solved(self, eval_results):\n",
    "        \"\"\"Validate the results\"\"\"\n",
    "\n",
    "        results = eval_results._results\n",
    "\n",
    "        # If any of the result scores are not a 1, return false\n",
    "        if len(results) == 0:\n",
    "            raise Exception(\"No results found\")\n",
    "\n",
    "        for result in results:\n",
    "            score = result['evaluation_results'][\"results\"][0].score\n",
    "            if score != 1:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _test_rule(self, rule: Rule):\n",
    "        \"\"\"Evaluate a given rule\"\"\"\n",
    "        print(f'\\nTesting rule: \"{rule.prompt}\"')\n",
    "        self.current_rule = rule\n",
    "\n",
    "        self.current_prompt = self._build_prompt(self.current_rule)\n",
    "\n",
    "        results = evaluate(\n",
    "            self._predict,\n",
    "            data=self.dataset_name,\n",
    "            evaluators=[self._evaluate_correctness],\n",
    "            experiment_prefix=f\"Attempt-{self.attempts}\",\n",
    "        )\n",
    "\n",
    "        self.attempts += 1\n",
    "\n",
    "        return results\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the promptnado\"\"\"\n",
    "        print(f\"Running Promptnado with instruction: {self.instruction}\")\n",
    "        self._create_dataset()\n",
    "\n",
    "        while not self.solved and self.attempts < self.max_attempts:\n",
    "            try:\n",
    "                self._generate_rules()\n",
    "                for rule in self.rules:\n",
    "                    if self.attempts > self.max_attempts:\n",
    "                        print(\"Max attempts reached\")\n",
    "                        return\n",
    "                    results = self._test_rule(rule)\n",
    "                    if self._is_solved(results):\n",
    "                        self.results = results\n",
    "                        self.solved = True\n",
    "                        self.successful_prompt = self.current_prompt\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Fatal error encountered: {e}\")\n",
    "                return  # Exit the while loop on error\n",
    "\n",
    "        print(\"\\n\\nSolved!! Current prompt can be found at `self.successful_prompt`\\n\\n\")\n",
    "\n",
    "        print(\n",
    "            f\"Successful prompt:\\n====================\\n{self.current_prompt}\\n=================\")\n",
    "        print(self.results._manager._experiment.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Promptnado with instruction: The agent should only respond in English.\n",
      "Created dataset: Promptnado_36011 with 2 examples\n",
      "Generated 5 rules\n",
      "\n",
      "[Rule(reasoning='This prompt explicitly states that the assistant should respond solely in English, which aligns with the instruction provided.', prompt='You should respond only in English.'), Rule(reasoning='By phrasing the rule as a directive, it reinforces the requirement that all communication must occur in English.', prompt='All responses must be in English only.'), Rule(reasoning='This version emphasizes clarity and understanding, ensuring that the assistant knows to use English for all interactions.', prompt='Communicate exclusively in English for all responses.'), Rule(reasoning='This version of the prompt directly instructs the assistant to use English as the sole language for replies, making the requirement very clear.', prompt='Respond in English and avoid using any other languages.'), Rule(reasoning='This prompt explicitly restricts the language of the responses to English, leaving no ambiguity about the language to be used.', prompt='You are required to respond in English without exception.')]\n",
      "\n",
      "Testing rule: \"You should respond only in English.\"\n",
      "Interpolated prompt:\n",
      "\n",
      "You are a helpful assistant. \n",
      "\n",
      "Rules:\n",
      "- You are only allowed to talk about coding\n",
      "- You should respond only in English.\n",
      "- Try to be concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camron/Documents/Dev/promptnado/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Attempt-1-4be5a837' at:\n",
      "https://smith.langchain.com/o/d967989d-4221-53db-b0a5-665b504acba2/datasets/0365f92d-e4fb-4921-83b6-210b3266c5e3/compare?selectedSessions=0b33ebdb-6f40-4e0b-b184-cabd893fb550\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: [SystemMessage(content='You are a helpful assistant. \\n\\nRules:\\n- You are only allowed to talk about coding\\n- You should respond only in English.\\n- Try to be concise'), HumanMessage(content='Hi there!')]\n",
      "Messages: [SystemMessage(content='You are a helpful assistant. \\n\\nRules:\\n- You are only allowed to talk about coding\\n- You should respond only in English.\\n- Try to be concise'), AIMessage(content='Hola, como estas?')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Solved!! Current prompt can be found at `self.successful_prompt`\n",
      "\n",
      "\n",
      "Successful prompt:\n",
      "====================\n",
      "You are a helpful assistant. \n",
      "\n",
      "Rules:\n",
      "- You are only allowed to talk about coding\n",
      "- You should respond only in English.\n",
      "- Try to be concise\n",
      "=================\n",
      "https://smith.langchain.com/o/d967989d-4221-53db-b0a5-665b504acba2/projects/p/0b33ebdb-6f40-4e0b-b184-cabd893fb550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pn = Promptnado(example_system_prompt, example_instruction,\n",
    "                examples, max_attempts=2)\n",
    "pn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running with tools\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class RespondToUser(BaseModel):\n",
    "    \"\"\"A tool to use\"\"\"\n",
    "    response: str = Field(description=\"Your response to the user\")\n",
    "\n",
    "\n",
    "llm = init_chat_model(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([RespondToUser])\n",
    "\n",
    "\n",
    "pn = Promptnado(example_system_prompt, example_instruction,\n",
    "                examples, max_attempts=2)\n",
    "# pn.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
